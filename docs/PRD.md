# PRD：语义嵌入与检索 MCP 服务（升级版）

## 1. 引言（背景与目标）
- 背景：当前项目为一个基于智谱 AI GLM 嵌入模型的 MCP 服务，能够将文本转为高维向量，用于语义相似度与搜索。但现阶段仅支持“生成向量”的单一能力，应用价值呈现不够。
- 目标：在保持“MCP 服务”定位不变的前提下，扩展自然语言指令，新增“文档索引与语义搜索”能力，形成可演示的闭环场景（索引->搜索），提升应用价值与技术先进性，并体现对蓝耘 MCP 平台生态的推动作用。

## 2. 目标用户画像
- 平台侧开发者：在蓝耘 MCP 平台上构建应用（如客服、知识问答、内部工具）的开发者，需快速集成语义搜索能力。
- 企业终端用户（通过上层应用间接使用）：研发、客服、新人等在海量内部文档中检索信息的员工。

## 3. 核心价值主张
- 让任意应用“低成本、快速”拥有先进的语义搜索能力：通过 MCP 工具以自然语言发指令即可完成文档索引与搜索，无需开发者自行搭建复杂的向量检索基础设施。

## 4. 功能需求
### 4.1 功能列表
1) 向量生成（已具备）
- 输入文本，返回高维嵌入向量（基于智谱 GLM 嵌入模型）。
2) 文档索引（新增）
- 自然语言指令示例：
  - “索引这个文档 <本地路径或URL>”
  - “把 docs/policies 这个文件夹都索引了，集合名设为 kb_policies”
- 行为：读取文档 -> 分块 -> 生成嵌入 -> 存入向量数据库（ChromaDB）。
- 元数据：保存 source（文件名/路径/URL）、chunk_id、offset、集合名（kb_name）等。
3) 语义搜索（新增）
- 自然语言指令示例：
  - “在知识库里搜索‘差旅报销怎么走’”
  - “搜索 ‘请假申请’ top=5 in kb=kb_policies”
- 行为：将查询转为向量 -> 在指定集合中相似度检索 -> 返回前 K 条匹配片段（含来源、相似度、片段文本）。

### 4.2 指令格式（建议）
- 索引：
  - “索引 <path_or_url> [kb=<name>] [chunk_size=500] [overlap=50]”
- 搜索：
  - “搜索 <query> [top=5] [kb=<name>]”
- 可选集合管理（Should-have）：
  - “创建集合 kb=kb_xxx”
  - “清空集合 kb=kb_xxx”
  - “统计集合 kb=kb_xxx”

### 4.3 用例与流程
- 用例A：索引文档
  - 前置：ChromaDB 客户端可用；目标文档可访问。
  - 步骤：
    1. 用户发出“索引 path/to/doc.md kb=kb_default”
    2. 服务读取文档 -> 分块（按中文标点/长度） -> 嵌入
    3. 将 chunks 文本 + 向量 + 元数据写入 Chroma 集合
    4. 返回“成功：doc.md 分块 15 条，写入集合 kb_default”
  - 异常：文件不存在/不可读；嵌入 API 失败；DB 写入失败 —— 需明确错误消息与重试策略
- 用例B：语义搜索
  - 前置：集合中已有索引数据
  - 步骤：
    1. 用户发出“搜索 ‘如何报销差旅’ top=3 in kb=kb_default”
    2. 服务将查询嵌入 -> 相似度检索 -> 取 TopK
    3. 返回结构化结果（来源、相似度、片段预览、命中位置）
  - 异常：集合为空/不存在 -> 友好提示先执行索引

## 5. 非功能性需求
- 性能：中等规模（1万 chunks）内，查询延迟 < 2 秒。
- 易用性：自然语言指令直观；结果输出清晰（含来源、片段、相似度）。
- 安全性：
  - API Key 校验（调用外部嵌入服务与内部指令需要有效凭证）
  - 路径沙箱：限制可索引的本地目录白名单（避免越权读取敏感路径）
  - 指令白名单与参数校验（防止构造恶意命令）
- 可靠性：对嵌入调用/存储读写设置超时与重试；关键操作日志；错误消息可定位。
- 可扩展性：存储层可替换（Milvus/Qdrant/PGVector）；嵌入模型可配置。

## 6. 范围与限制
- 本期范围（Must-have）：
  - 集成 ChromaDB（内存或本地持久化目录）
  - 支持文本/Markdown 文件索引与搜索
  - 自然语言指令：索引、搜索；（集合管理为 Should-have）
  - 基础安全与错误处理
- 暂不纳入（Out of Scope）：
  - GUI、REST 网关、多租户、复杂权限体系
  - 大规模分布式部署与水平扩展
- 假设与依赖：
  - Python 3.8+；可安装依赖（chromadb 等）
  - 可用的智谱 AI 嵌入 API Key 与稳定网络

## 7. 平台结合与演示方案
- 部署：发布至蓝耘 MCP 广场，作为“语义处理引擎”能力中心，供其他应用调用。
- Demo 场景（线上/线下答辩）：
  1) 通过 MCP 聊天：执行“索引 docs/policies/*.md 到 kb_policies”
  2) 执行“搜索 ‘交通补贴标准’ in kb=kb_policies top=3”
  3) 展示输出结果（含来源文件与片段），说明如何赋能客服/知识问答/内部搜索
- 价值论述：为平台其他应用提供即插即用的语义检索底座，降低接入门槛，促进生态繁荣（平台结合度 10% 加分点）。

## 8. 技术架构（示意）
```mermaid
graph TD
  subgraph 离线/准实时 索引
    A[文档: .txt/.md/URL] --> B[分块 & 预处理]
    B --> C[智谱GLM 嵌入]
    C --> D[(Chroma 集合)]
  end

  subgraph 在线 搜索
    U[用户(自然语言指令)] --> R[指令解析 & 路由]
    R --> Q[查询嵌入]
    Q --> D
    D --> S[TopK 结果(来源/相似度/片段)]
    S --> U
  end
```

## 9. 实施规划（里程碑）
- M1：集成 ChromaDB；实现分块模块；完成“索引”指令
- M2：完成“搜索”指令；输出结构化结果
- M3：安全与错误处理完善；准备演示数据与脚本
- M4：PPT 及答辩材料

## 10. 未来展望
- 格式扩展：PDF/DOCX/网页抓取
- 检索增强：Rerank、多集合/多租户隔离
- RAG 问答：结合大模型生成带引用的回答
- 安全增强：细粒度权限、审计日志、数据脱敏